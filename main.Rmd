---
title: "Proyecto Grupal - Análisis de Datos I"
author: 
  - Luis Fernando Amey Apuy - C20470
  - Javier Hernández Navarro - C13674
  - Gustavo Alberto Amador Fonseca - C20459
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    self_contained: true
    highlight: tango
---

# Librerías y carga de datos
```{r}
source("cod/r/setup.R")
```

```{r}
gen <- scrapW("genfiltrada")
herra <- scrapT("herraII_08-07-24")
```

# Gráficos
```{r, warning=FALSE}
cuentas <- gen %>%
  mutate(mes = floor_date(as.Date(dia), "month")) %>%
  count(mes)

# Gráfico con la cantidad de mensajes por mes y año
ggplot(cuentas, aes(x = mes, y = n)) +
  geom_line(color = "salmon", size = 1) +
  geom_point(color = "salmon", size = 2) + 
  labs(x = "Mes-Año",
       y = "Cantidad de mensajes") +
  theme_minimal()

```

```{r}
# Gráfico con las horas registradas por día
ggplot(gen, aes(x = dia, y = hora)) +
  geom_point(color = "darkblue", alpha = 0.6) +
  labs(x = "Día",
       y = "Hora (seg)") +
  theme_minimal()

```

```{r}
cuentas <- gen%>%count(autor) %>% arrange(desc(n))
cuentas$autor <- factor(cuentas$autor, levels = cuentas$autor)
cuentas <- cuentas[cuentas$n >70,]

# Gráfico con el top de autores con más mensajes
ggplot(cuentas, aes(x = autor, y = n)) +
  geom_col(fill = "darkorange", color="black") +
  labs(x = "Autores",
       y = "Cantidad de mensajes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.8))
```

```{r, warning =FALSE}
cuentas <- gen%>%count(hour(hora)) %>% arrange(desc(n))

# Gráfico con la cantidad de mensajes por hora
ggplot(cuentas, aes(x = `hour(hora)`, y = n)) +
  geom_col(fill = "steelblue", color="darkblue") +
  labs(x = "Horas",
       y = "Cantidad de mensajes") +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 0.8))
```

```{r}
copia <- gen
rangos <- gen %>%
  group_by(autor) %>%
  summarise(rango = max(hora) - min(hora)) %>%
  arrange(rango)

# Reordenar el factor 'autor' según el rango
copia$autor <- factor(gen$autor, levels = rangos$autor)

# Graficar boxplot
ggplot(copia, aes(y = autor, x = hora / 3600)) +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  labs(x = "Hora",
       y = "Autor") +
  theme_minimal()
```

```{r}
cuentas <- gen %>% group_by(autor) %>% 
  summarise(m_editados = sum(editado)) %>% 
  arrange(desc(m_editados))
cuentas <- cuentas[cuentas$m_editados >0,]
cuentas$autor <- factor(cuentas$autor, levels = cuentas$autor)
ggplot(cuentas, aes(x = autor, y = m_editados)) +
  geom_col(fill = "darkorange", color="black") +
  labs(title = "Mayor cantidad de mensajes editados",
       x = "Autores",
       y = "Número de mensajes editados") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.8))

```

# Mapa de palabras
```{r}
palabras <- gen$mensaje
mensajes_clean <- gsub("[[:punct:]]", "", tolower(palabras))
totales <- data.frame(palabras = unlist(strsplit(mensajes_clean, "\\s+")))
cuentas <- totales %>% count(palabras)
```

```{r}
wordcloud(words = cuentas$palabras,
          freq = cuentas$n,
          min.freq = 8,
          colors = colorRampPalette(brewer.pal(8, "Dark2"))(50),
          random.order = FALSE)
```

# Preparación para clusterización
Se hará un caso puro sin eliminación y el otro caso con selección
## Selección de mensajes significativos
Los mensajes significativos serán todos aquellos que no tengan stickers, 
imágenes, documentos etc. Todos estos mensajes deberían ser completamente
inútiles para un análisis, puesto que solo contienen eso.

```{r}
gen_c <- gen
gen_c$id <- 1:3675
copia <- gen_c %>%
  filter(!grepl("sticker omitido|imagen omitida|Se eliminó este mensaje|documento omitido|Cambió tu código de seguridad|Video omitido|añadió|https|usando el enlace de invitación|eliminó|cambió su número de teléfono", mensaje))
```
Se deciden eliminar los links puesto que después de una revisión manual son muy 
pocos los casos significativos 

## Eliminación de encuestas 
```{r}
copia <- copia %>% 
  filter(!grepl("ENCUESTA:|OPCIÓN:", mensaje))
```

## Eliminación del autor Gen Filtrada
```{r}
copia <- copia[copia$autor != 'Gen Filtrada',]
```

## Tokenización de las palabras
```{r}
tokens <- copia %>%
  unnest_tokens(palabras, mensaje)
```

## Eliminación de las menciones (@numtelefono) y enteros
```{r}
tokens <- tokens %>%
  filter(!grepl("^\\d+$", palabras))
```

## Eliminación de palabras monótonas
```{r}
palabras <- copia$mensaje
mensajes_clean <- gsub("[[:punct:]]", "", tolower(palabras))
totales <- data.frame(palabras = unlist(strsplit(mensajes_clean, "\\s+")))
cuentas <- totales %>% count(palabras)
```

### Mapeo de palabras con eliminaciones
```{r, warning=FALSE}
wordcloud(words = cuentas$palabras,
          freq = cuentas$n,
          min.freq = 10,
          colors = colorRampPalette(brewer.pal(8, "Dark2"))(50),
          random.order = FALSE)
```

### Eliminación de palabras más repetidas sin sentimiento (43 veces o más)
```{r}
cuentas <- cuentas[cuentas$n >= 43,]
cuentas <- cuentas %>% mutate(get_nrc_sentiment(palabras, lang="spanish"))
```

```{r, warning =FALSE}
cuentas %>%
  summarise(across(3:ncol(.), sum, na.rm = TRUE))
```
Al no haber sentimientos, se pueden optar por remover en este caso. 

```{r}
tokens <- tokens %>%
  anti_join(cuentas, by = "palabras")
```

### Visualización después de eliminación
```{r}
palabras <- tokens$palabras
mensajes_clean <- gsub("[[:punct:]]", "", tolower(palabras))
totales <- data.frame(palabras = unlist(strsplit(mensajes_clean, "\\s+")))
cuentas <- totales %>% count(palabras)
```

```{r, warning=FALSE}
pdf("res/wordcloud.pdf", width = 8, height = 6)

wordcloud(words = cuentas$palabras,
          freq = cuentas$n,
          min.freq = 8,
          scale = c(1.8, 0.2),
          colors = colorRampPalette(brewer.pal(8, "Dark2"))(50),
          random.order = FALSE)

dev.off()

```

# Modelos
## Modelo original (sin eliminación)
```{r}
mdl_o <- gen_c %>%
  unnest_tokens(palabras, mensaje)
```

## Modelo filtrado (con eliminación)
Se puede notar una reducción de la mitad de las observaciones
```{r}
mdl_s <- tokens
```

### Acomodo del ambiente
```{r}
rm(copia, 
   cuentas,
   rangos, 
   tokens, 
   totales,
   palabras,
   mensajes_clean)
```

## Sentimientos de los modelos
```{r}
t <- proc.time()
mdl_o <- mdl_o %>% mutate(get_nrc_sentiment(palabras, lang="spanish"))
mdl_s <- mdl_s %>% mutate(get_nrc_sentiment(palabras, lang="spanish"))
# proc.time() - t
```

## Sentimientos generales
```{r}
mdl_o %>%
  summarise(across(7:ncol(.), sum, na.rm = TRUE))
```

```{r}
mdl_s %>%
  summarise(across(7:ncol(.), sum, na.rm = TRUE))
```

## Agrupación por mensajes de nuevo
```{r}
mdl_o <- mdl_o %>%
  group_by(id) %>%
  summarise(across(anger:positive, sum), .groups = "drop")

mdl_s <- mdl_s %>%
  group_by(id) %>%
  summarise(across(anger:positive, sum), .groups = "drop")
```

```{r}
mdl_o <- inner_join(gen_c, mdl_o, by = join_by(id))
mdl_s <- inner_join(gen_c, mdl_s, by = join_by(id))
```

Hay menos mensajes en el original puesto que los emojis solos no se tokenizan.

```{r}
rm(gen_c)
```

# Clusterización
## Eliminación de las variables no significativas (sin sentimientos)
Se procederá a dividir los modelos más, un lado sin los sentimientos en 0

```{r}
ind_o <- rowSums(mdl_o[,7:15] != 0) != 0
ind_s <- rowSums(mdl_s[,7:15] != 0) != 0
```

```{r}
mdl_1 <- mdl_o
mdl_2 <- mdl_s
mdl_3 <- mdl_o[ind_o,]
mdl_4 <- mdl_s[ind_s,]
```

```{r}
rm(ind_o,
   ind_s,
   mdl_o,
   mdl_s)
```

## Funciones de clusterización
```{r}
colocar <- function(ind, centroids, past){
  dist <- sapply(1:nrow(centroids), function(x) sum((centroids[x,] - ind)^2))
  posibles <- which(dist == min(dist))
  if(length(posibles) == 1){
    return(posibles[1])
  } else if(sum(posibles == past) > 0){
    return(past)
  } else {
    return(posibles[1])
  }
}
```

### Kmeans
```{r}
kmeans <- function(nodes, df){
  len <- nrow(df)
  ids <- sample(len, nodes)
  val <- df[,7:16]
  centr <- val[ids,]
  clusters <- rep(0, len)
  clusters[ids] <- 1:nodes
  past <- clusters
  numiter <- 0
  while(numiter < 100){
    clusters <- sapply(1:len, function(x) colocar(val[x,],centr, past[x]))
    print(abs(sum(clusters!=past)))
    if(abs(sum(clusters!=past)) == 0){
      break
    } else{
      past <- clusters
    }
    numiter <- numiter + 1
    centr <- t(sapply(1:nodes, function(x) 
      sapply(1:9, function (y) mean(val[clusters == x, y]))
    ))
  }
  return(list(clusters, centr))
}
```

### Kmedians
```{r}
kmedians <- function(nodes, df){
  len <- nrow(df)
  ids <- sample(len, nodes)
  val <- df[,7:16]
  centr <- val[ids,]
  clusters <- rep(0, len)
  clusters[ids] <- 1:nodes
  past <- clusters
  numiter <- 0
  while(numiter < 100){
    clusters <- sapply(1:len, function(x) colocar(val[x,],centr, past[x]))
    print(abs(sum(clusters!=past)))
    if(abs(sum(clusters!=past)) == 0){
      break
    } else{
      past <- clusters
    }
    numiter <- numiter + 1
    new_centr <- t(sapply(1:nodes, function(x) 
      sapply(1:9, function (y) median(val[clusters == x, y]))
    ))
    new_centr <- sapply(1:nodes, function(x) colocar(new_centr[x,], val[clusters == x, ], 0))
    centr <- t(sapply(1:nodes, function(x) val[clusters == x, ][new_centr[x],]))
    ids <- sapply(1:nodes, function(x) df[clusters == x, 6][new_centr[x]])
  }
  return(list(clusters, centr, ids))
}
```

### Prueba de kmeans
```{r}
t <- proc.time()
clusters <- 5
prueba_kmeans <- kmeans(clusters, mdl_4)
proc.time() - t
Q <- prueba_kmeans[[1]]
centr <- prueba_kmeans[[2]]
```

### Resumen clusters
```{r}
sapply(1:clusters, function(x) colSums(mdl_4[Q == x,7:16]))
```

```{r}
sapply(1:clusters, function(x) sum(Q == x))
```

### Prueba de kmedians
```{r}
t <- proc.time()
clusters <- 5
prueba_kmedians <- kmedians(clusters, mdl_4)
proc.time() - t
```

De este se pueden sacar las observaciones que son centroides para su interpretación
```{r}
mdl_4[mdl_4$id == prueba_kmedians[[3]], 5]
```

### Paralelización de las funciones
Sirve para hacer simulaciones y encontrar el set de clusters más usado
```{r}
kmeans_par <- function(n, clst, mdl, cores) {
  cl <- makeCluster(cores) 
  clusterExport(
    cl,
    varlist = c("clusters","mdl_1","mdl_2","mdl_3","mdl_4","kmeans","colocar"),
    envir = environment())
  resultados <- parSapply(cl, 1:n, function(x) kmeans(clst, mdl)[[2]])
  stopCluster(cl)
  return(resultados)
}
```

```{r}
kmedians_par <- function(n, clst, mdl_4, cores) {
  cl <- makeCluster(cores) 
  clusterExport(
    cl,
    varlist = c("clusters","mdl_1","mdl_2","mdl_3","mdl_4","kmedians","colocar"),
    envir = environment())
  resultados <- parSapply(cl, 1:n, function(x) kmedians(clst, mdl)[[3]])
  stopCluster(cl)
  return(resultados)
}
```

### Prueba algoritmo 
```{r}
t <- proc.time()
clusters <- 5
res5 <- kmedians_par(10, clusters, mdl_4, 5)
proc.time() - t
```

### Guardar resultados
```{r}
# write.csv(res2, "res/res2.csv")
# write.csv(res3, "res/res3.csv")
# write.csv(res4, "res/res4.csv")
# write.csv(res5, "res/res5.csv")
```

### Obtener el set de clusters moda para kmedians
```{r}
vec <- as.vector(sapply(data.frame(res5), function(x) x[[3]]))
# centr <- sapply(data.frame(res5), function(x) sort(x))
# df <- t(centr)
df <- apply(mtx, 1, paste, collapse = "-")
(tabla <- sort(table(df), decreasing = TRUE))
```

## Obtención de la clusterización óptima por medio del método del codo
```{r}
wcss <- function(nodes, df){
  res <- kmeans(i, df)
  points_c <- sapply(1:nodes, function(x) sum(res[[1]] == x))
  wcss <- sum(sapply(1:nodes, function(x) sum(sapply(
    1:points_c[x], function(y) sum((df[res[[1]] == x, 7:16][y,] - res[[2]][x,])^2)
  ))))
  return(wcss)
}
```

```{r}
t <- proc.time()
metrica <- data.frame(mdl1 = rep(0,10),
                      mdl2 = rep(0,10),
                      mdl3 = rep(0,10),
                      mdl4 = rep(0,10))
for(i in 1:10){
  print(i)
  metrica$mdl1[i] <- wcss(i, mdl_1)
  metrica$mdl2[i] <- wcss(i, mdl_2)
  metrica$mdl3[i] <- wcss(i, mdl_3)
  metrica$mdl4[i] <- wcss(i, mdl_4)
}
proc.time() - t
# write.csv(metrica, "res/metrica.csv")
```


```{r}
metrica_mean$x <- 1:10
metrica_mean <- metrica_mean %>%
  pivot_longer(cols = starts_with("mdl"), 
               names_to = "modelo", 
               values_to = "valor")
ggplot(metrica_mean, aes(x = x, y = valor, color = modelo)) +
  geom_line() +
  geom_point(show.legend = FALSE) +  
  scale_color_manual(values = c("mdl1" = "darkorange", 
                                "mdl2" = "cyan", 
                                "mdl3" = "red", 
                                "mdl4" = "blue"), 
                     labels = c("mdl1" = "Modelo 1", 
                                "mdl2" = "Modelo 2", 
                                "mdl3" = "Modelo 3", 
                                "mdl4" = "Modelo 4")) +
  theme_minimal() +
  labs(title = "Métrica WCSS con medias", 
       x = "clusters",
       y = "WCSS",
       color = "Modelos") +
  theme(legend.position = "right")
```



















