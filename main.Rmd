---
title: "Proyecto Grupal - Análisis de Datos I"
author: 
  - Luis Fernando Amey Apuy - C20470
  - Javier Hernández Navarro - C13674
  - Gustavo Alberto Amador Fonseca - C20459
date: "`r Sys.Date()`"
output:
  rmdformats::robobook:
    self_contained: true
    highlight: tango
---

# Librerías y carga de datos
```{r}
source("cod/r/setup.R")
```

```{r}
gen <- scrapW("genfiltrada")
herra <- scrapT("herraII_08-07-24")
```

# Gráficos
```{r, warning=FALSE}
cuentas <- gen %>%
  mutate(mes = floor_date(as.Date(dia), "month")) %>%
  count(mes)

ggplot(cuentas, aes(x = mes, y = n)) +
  geom_col(fill = "pink3", color = "red") +
  labs(title = "Cantidad de mensajes por mes",
       x = "Mes",
       y = "Frecuencia") +
  theme_minimal()

```

```{r}
ggplot(gen, aes(x = dia, y = hora)) +
  geom_point(color = "darkblue", alpha = 0.6) +
  labs(title = "Horas registradas por día",
       x = "Día",
       y = "Hora (seg)") +
  theme_minimal()

```

```{r}
cuentas <- gen%>%count(autor) %>% arrange(desc(n))
cuentas$autor <- factor(cuentas$autor, levels = cuentas$autor)
cuentas <- cuentas[cuentas$n >70,]
ggplot(cuentas, aes(x = autor, y = n)) +
  geom_col(fill = "darkorange", color="black") +
  labs(title = "Mayor cantidad de mensajes",
       x = "Autores",
       y = "Número de mensajes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.8))
```

```{r, warning =FALSE}
cuentas <- gen%>%count(hour(hora)) %>% arrange(desc(n))
ggplot(cuentas, aes(x = `hour(hora)`, y = n)) +
  geom_col(fill = "steelblue", color="blue") +
  labs(title = "Cantidad de mensajes por hora del día",
       x = "Horas",
       y = "Número de mensajes") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.8))
```

```{r}
copia <- gen
rangos <- gen %>%
  group_by(autor) %>%
  summarise(rango = max(hora) - min(hora)) %>%
  arrange(rango)

# Reordenar el factor 'autor' según el rango
copia$autor <- factor(gen$autor, levels = rangos$autor)

# Graficar boxplot
ggplot(copia, aes(y = autor, x = hora / 3600)) +
  geom_boxplot(fill = "lightblue", color = "darkblue") +
  labs(title = "Distribución de horas por autor (ordenado por rango)",
       x = "Hora",
       y = "Autor") +
  theme_minimal()
```

```{r}
cuentas <- gen %>% group_by(autor) %>% 
  summarise(m_editados = sum(editado)) %>% 
  arrange(desc(m_editados))
cuentas <- cuentas[cuentas$m_editados >0,]
cuentas$autor <- factor(cuentas$autor, levels = cuentas$autor)
ggplot(cuentas, aes(x = autor, y = m_editados)) +
  geom_col(fill = "darkorange", color="black") +
  labs(title = "Mayor cantidad de mensajes editados",
       x = "Autores",
       y = "Número de mensajes editados") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 0.8))

```

# Mapa de palabras
```{r}
palabras <- gen$mensaje
mensajes_clean <- gsub("[[:punct:]]", "", tolower(palabras))
totales <- data.frame(palabras = unlist(strsplit(mensajes_clean, "\\s+")))
cuentas <- totales %>% count(palabras)
```

```{r}
wordcloud(words = cuentas$palabras,
          freq = cuentas$n,
          min.freq = 8,
          colors = colorRampPalette(brewer.pal(8, "Dark2"))(50),
          random.order = FALSE)
```

# Preparación para clusterización
Se hará un caso puro sin eliminación y el otro caso con selección
## Selección de mensajes significativos
Los mensajes significativos serán todos aquellos que no tengan stickers, 
imágenes, documentos etc. Todos estos mensajes deberían ser completamente
inútiles para un análisis, puesto que solo contienen eso.

```{r}
gen_c <- gen
gen_c$id <- 1:3675
copia <- gen_c %>%
  filter(!grepl("sticker omitido|imagen omitida|Se eliminó este mensaje|documento omitido|Cambió tu código de seguridad|Video omitido|añadió|https|usando el enlace de invitación|eliminó|cambió su número de teléfono", mensaje))
```
Se deciden eliminar los links puesto que después de una revisión manual son muy 
pocos los casos significativos 

## Eliminación de encuestas 
```{r}
copia <- copia %>% 
  filter(!grepl("ENCUESTA:|OPCIÓN:", mensaje))
```

## Eliminación del autor Gen Filtrada
```{r}
copia <- copia[copia$autor != 'Gen Filtrada',]
```

## Tokenización de las palabras
```{r}
tokens <- copia %>%
  unnest_tokens(palabras, mensaje)
```

## Eliminación de las menciones (@numtelefono) y enteros
```{r}
tokens <- tokens %>%
  filter(!grepl("^\\d+$", palabras))
```

## Eliminación de palabras monótonas
```{r}
palabras <- copia$mensaje
mensajes_clean <- gsub("[[:punct:]]", "", tolower(palabras))
totales <- data.frame(palabras = unlist(strsplit(mensajes_clean, "\\s+")))
cuentas <- totales %>% count(palabras)
```

### Mapeo de palabras con eliminaciones
```{r, warning=FALSE}
wordcloud(words = cuentas$palabras,
          freq = cuentas$n,
          min.freq = 10,
          colors = colorRampPalette(brewer.pal(8, "Dark2"))(50),
          random.order = FALSE)
```

### Eliminación de palabras más repetidas sin sentimiento (43 veces o más)
```{r}
cuentas <- cuentas[cuentas$n >= 43,]
cuentas <- cuentas %>% mutate(get_nrc_sentiment(palabras, lang="spanish"))
```

```{r, warning =FALSE}
cuentas %>%
  summarise(across(3:ncol(.), sum, na.rm = TRUE))
```
Al no haber sentimientos, se pueden optar por remover en este caso. 

```{r}
tokens <- tokens %>%
  anti_join(cuentas, by = "palabras")
```

### Visualización después de eliminación
```{r}
palabras <- tokens$palabras
mensajes_clean <- gsub("[[:punct:]]", "", tolower(palabras))
totales <- data.frame(palabras = unlist(strsplit(mensajes_clean, "\\s+")))
cuentas <- totales %>% count(palabras)
```

```{r, warning=FALSE}
wordcloud(words = cuentas$palabras,
          freq = cuentas$n,
          min.freq = 8,
          scale = c(1.8, 0.2),
          colors = colorRampPalette(brewer.pal(8, "Dark2"))(50),
          random.order = FALSE)
```

# Modelos
## Modelo original (sin eliminación)
```{r}
mdl_o <- gen_c %>%
  unnest_tokens(palabras, mensaje)
```

## Modelo filtrado (con eliminación)
Se puede notar una reducción de la mitad de las observaciones
```{r}
mdl_s <- tokens
```

### Acomodo del ambiente
```{r}
rm(copia, 
   cuentas,
   rangos, 
   tokens, 
   totales,
   palabras,
   mensajes_clean)
```

## Sentimientos de los modelos
```{r}
mdl_o <- mdl_o %>% mutate(get_nrc_sentiment(palabras, lang="spanish"))
mdl_s <- mdl_s %>% mutate(get_nrc_sentiment(palabras, lang="spanish"))
```

## Sentimientos generales
```{r}
mdl_o %>%
  summarise(across(7:ncol(.), sum, na.rm = TRUE))
```

```{r}
mdl_s %>%
  summarise(across(7:ncol(.), sum, na.rm = TRUE))
```

## Agrupación por mensajes de nuevo
```{r}
mdl_o <- mdl_o %>%
  group_by(id) %>%
  summarise(across(anger:positive, sum), .groups = "drop")

mdl_s <- mdl_s %>%
  group_by(id) %>%
  summarise(across(anger:positive, sum), .groups = "drop")
```

```{r}
mdl_o <- inner_join(gen_c, mdl_o, by = join_by(id))
mdl_s <- inner_join(gen_c, mdl_s, by = join_by(id))
```

Hay menos mensajes en el original puesto que los emojis solos no se tokenizan.

```{r}
rm(gen_c)
```

# Clusterización
## Eliminación de las variables no significativas (sin sentimientos)
Se procederá a dividir los modelos más, un lado sin los sentimientos en 0

```{r}
ind_o <- rowSums(mdl_o[,7:15] != 0) != 0
ind_s <- rowSums(mdl_s[,7:15] != 0) != 0
```

```{r}
mdl_1 <- mdl_o
mdl_2 <- mdl_s
mdl_3 <- mdl_o[ind_o,]
mdl_4 <- mdl_s[ind_s,]
```

```{r}
rm(ind_o,
   ind_s,
   mdl_o,
   mdl_s)
```

```{r}
colocar <- function(ind, centroids, past){
  dist <- sapply(1:nrow(centroids), function(x) sum((centroids[x,] - ind)^2))
  posibles <- which(dist == min(dist))
  if(length(posibles) == 1){
    return(posibles[1])
  } else if(sum(posibles == past) > 0){
    return(past)
  } else {
    return(posibles[1])
  }
}
```

```{r}
kmeans <- function(nodes, df){
  len <- nrow(df)
  ids <- sample(len, nodes)
  val <- df[,7:16]
  centr <- val[ids,]
  clusters <- rep(0, len)
  clusters[ids] <- 1:nodes
  past <- clusters
  numiter <- 0
  while(numiter < 100){
    clusters <- sapply(1:len, function(x) colocar(val[x,],centr, past[x]))
    # print(abs(sum(clusters!=past)))
    if(abs(sum(clusters!=past)) == 0){
      break
    } else{
      past <- clusters
    }
    numiter <- numiter + 1
    new_centr <- t(sapply(1:nodes, function(x) 
      sapply(1:9, function (y) mean(val[clusters == x, y]))
    ))
    # new_centr <- sapply(1:nodes, function(x) colocar(new_centr[x,], val[clusters == x, ], 0))
    # centr <- t(sapply(1:nodes, function(x) val[clusters == x, ][new_centr[x],]))
    centr <- new_centr
    ids <- sapply(1:nodes, function(x) df[clusters == x, 6][new_centr[x]])
  }
  return(centr)
}
```

```{r}
t <- proc.time()
clusters <- 4
res <- kmeans(clusters, mdl_4)
proc.time() - t
Q <- res[[1]]
centr <- res[[2]]
```

## Resumen clusters
```{r}
sapply(1:clusters, function(x) colSums(mdl_3[Q == x,7:16]))
```

```{r}
sapply(1:clusters, function(x) sum(Q == x))
```

```{r}
kmeans_par <- function(n, clst, mdl_4, cores) {
  cl <- makeCluster(cores) 
  clusterExport(
    cl,
    varlist = c("clusters", "mdl_4", "kmeans", "colocar"),
    envir = environment())
  resultados <- parSapply(cl, 1:n, function(x) kmeans(clst, mdl_4))
  stopCluster(cl)
  return(resultados)
}
```

```{r}
t <- proc.time()
clusters <- 5
res5 <- kmeans_par(100, clusters, mdl_4, 5)
proc.time() - t
```

```{r}
centr <- sapply(data.frame(res4), function(x) sort(x))
df <- t(centr)
df <- apply(df, 1, paste, collapse = "-")
(tabla <- sort(table(df), decreasing = TRUE))
```

```{r}
wcss <- function(nodes, df){
  res <- kmeans(i, df)
  points_c <- sapply(1:nodes, function(x) sum(res[[1]] == x))
  wcss <- sum(sapply(1:nodes, function(x) sum(sapply(
    1:points_c[x], function(y) sum((df[res[[1]] == x, 7:16][y,] - res[[2]][x,])^2)
  ))))
  return(wcss)
}
```

```{r}
t <- proc.time()
metrica <- rep(0, 10)
for(i in 1:10){
  print(i)
  metrica[i] <- wcss(i, mdl_4)
}
proc.time() - t
```



















